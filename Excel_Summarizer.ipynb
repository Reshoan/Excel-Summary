{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "from pyngrok import ngrok\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "from io import BytesIO\n",
        "import re\n",
        "import time\n",
        "from openpyxl import load_workbook\n",
        "import os\n",
        "\n",
        "# ---------------- STREAMLIT APP ---------------- #\n",
        "\n",
        "st.title(\"Excel Form Processor\")\n",
        "\n",
        "# Step 1: Upload Excel file\n",
        "uploaded_file = st.file_uploader(\"Upload an Excel file\", type=[\"xlsx\"])\n",
        "\n",
        "if uploaded_file:\n",
        "\n",
        "    original_file_name = os.path.basename(uploaded_file.name)\n",
        "\n",
        "    # Use session_state to avoid reprocessing on download click\n",
        "    if 'processed_output' not in st.session_state:\n",
        "\n",
        "        xls = pd.ExcelFile(uploaded_file)\n",
        "\n",
        "        # Ensure required sheets exist\n",
        "        required_sheets = [\"formFields\", \"transitions\", \"workflowSlas\"]\n",
        "        for sheet in required_sheets:\n",
        "            if sheet not in xls.sheet_names:\n",
        "                st.error(f\"Missing required sheet: '{sheet}'\")\n",
        "                st.stop()\n",
        "\n",
        "        # ---------------- Load Sheets ---------------- #\n",
        "        df = pd.read_excel(uploaded_file, sheet_name=\"formFields\")\n",
        "        transitions_df = pd.read_excel(uploaded_file, sheet_name=\"transitions\")\n",
        "        workflow_slas_df = pd.read_excel(uploaded_file, sheet_name=\"workflowSlas\")\n",
        "\n",
        "        # Required column names\n",
        "        field_name_col = \"name\"\n",
        "        field_type_col = \"input_type\"\n",
        "        field_order_col = \"order\"\n",
        "        form_col = \"formName\"\n",
        "\n",
        "        fixed_category_cols = [\n",
        "            \"is_editable\", \"is_hidden\", \"is_required\", \"is_nullable\",\n",
        "            \"is_multiselect\", \"is_richtext\", \"editor_height\",\n",
        "            \"is_encrypted\", \"is_conditional\"\n",
        "        ]\n",
        "        selected_category_cols = [c for c in fixed_category_cols if c in df.columns]\n",
        "\n",
        "        # Load mapping sheet\n",
        "        field_mapping_df = pd.DataFrame(columns=[\"formName\", \"fieldName\"])\n",
        "        if \"fieldMapping\" in xls.sheet_names:\n",
        "            field_mapping_df = pd.read_excel(uploaded_file, sheet_name=\"fieldMapping\")\n",
        "\n",
        "        # Process forms automatically\n",
        "        all_forms = sorted(df[form_col].dropna().unique())\n",
        "        num_forms = len(all_forms)\n",
        "\n",
        "        output = BytesIO()\n",
        "        progress_bar = st.progress(0)\n",
        "\n",
        "        uploaded_file.seek(0)\n",
        "        wb = load_workbook(uploaded_file)\n",
        "\n",
        "        # ---------- Live sheet creation UI ----------\n",
        "        sheet_list_placeholder = st.empty()\n",
        "        created_sheets = []\n",
        "\n",
        "        st.info(f\"Created {num_forms + 1} sheets\")  # +1 for Transition_mapping\n",
        "\n",
        "        # ============================================================\n",
        "        #                     PROCESS FORMS\n",
        "        # ============================================================\n",
        "\n",
        "        for i, full_form_name in enumerate(all_forms):\n",
        "\n",
        "            parts = full_form_name.split(\"_\")\n",
        "            if len(parts) > 3:\n",
        "                middle_parts = parts[2:-1]\n",
        "                short_name = \"_\".join(middle_parts)\n",
        "            else:\n",
        "                short_name = full_form_name\n",
        "\n",
        "            safe_short_name = re.sub(r'[\\\\/*?:\\[\\]]', '_', short_name)[:31]\n",
        "\n",
        "            form_df = df[df[form_col] == full_form_name].sort_values(by=field_order_col)\n",
        "            final_df = form_df[[field_name_col, field_type_col, field_order_col]].copy()\n",
        "\n",
        "            # Add Repeater column\n",
        "            repeater_list = []\n",
        "            filtered_mapping = field_mapping_df[field_mapping_df['formName'] == full_form_name]\n",
        "            mapped_fields = set(filtered_mapping['fieldName'].dropna())\n",
        "            for field in final_df[field_name_col]:\n",
        "                repeater_list.append(\"Yes\" if field in mapped_fields else \"\")\n",
        "            final_df.insert(len(final_df.columns), \"Repeater\", repeater_list)\n",
        "\n",
        "            # Add Categories column\n",
        "            if selected_category_cols:\n",
        "                categories_list = []\n",
        "                for idx, row in form_df.iterrows():\n",
        "                    selected = [col for col in selected_category_cols if row.get(col) == 1]\n",
        "                    selected.sort()\n",
        "                    categories_list.append(\",\".join(selected) if selected else \"\")\n",
        "                final_df['Categories'] = categories_list\n",
        "\n",
        "            if safe_short_name in wb.sheetnames:\n",
        "                wb.remove(wb[safe_short_name])\n",
        "            ws = wb.create_sheet(title=safe_short_name)\n",
        "\n",
        "            ws.cell(row=1, column=1, value=\"Form\")\n",
        "            ws.cell(row=1, column=2, value=full_form_name)\n",
        "\n",
        "            for c_idx, header in enumerate(final_df.columns, start=1):\n",
        "                ws.cell(row=2, column=c_idx, value=header)\n",
        "            for r_idx, row in enumerate(final_df.values, start=3):\n",
        "                for c_idx, value in enumerate(row, start=1):\n",
        "                    ws.cell(row=r_idx, column=c_idx, value=value)\n",
        "\n",
        "            # Update progress\n",
        "            progress = int((i + 1) / num_forms * 100)\n",
        "            progress_bar.progress(progress)\n",
        "\n",
        "            # Update live sheet list\n",
        "            created_sheets.append(safe_short_name)\n",
        "            with sheet_list_placeholder.container():\n",
        "                st.markdown(\"**Sheets created so far:**\")\n",
        "                st.markdown(\n",
        "                    \"<div style='max-height:250px; overflow-y:auto;'>\"\n",
        "                    + \"<br>\".join([f\"{idx+1}. {name}\" for idx, name in enumerate(created_sheets)])\n",
        "                    + \"</div>\",\n",
        "                    unsafe_allow_html=True\n",
        "                )\n",
        "\n",
        "            time.sleep(0.05)\n",
        "\n",
        "        # After all forms done, remove the \"Sheets created so far\" info\n",
        "        sheet_list_placeholder.empty()\n",
        "\n",
        "        # ============================================================\n",
        "        #              TRANSITION_MAPPING SHEET\n",
        "        # ============================================================\n",
        "\n",
        "        transition_cols = [\n",
        "            \"name\",\n",
        "            \"workflowFromStateName\",\n",
        "            \"workflowToStateName\",\n",
        "            \"workflowFormName\",\n",
        "            \"fromToStateName\"\n",
        "        ]\n",
        "        transition_df = transitions_df[transition_cols].copy()\n",
        "\n",
        "        # Case-insensitive alphabetical sorting\n",
        "        transition_df.sort_values(\n",
        "            by=[\"workflowFromStateName\", \"workflowToStateName\"],\n",
        "            key=lambda col: col.str.lower(),\n",
        "            inplace=True\n",
        "        )\n",
        "\n",
        "        merged_df = pd.merge(\n",
        "            transition_df,\n",
        "            workflow_slas_df[\n",
        "                [\"workflowFromStateName\", \"workflowToStateName\", \"sla_time\", \"sla_time_type\"]\n",
        "            ],\n",
        "            on=[\"workflowFromStateName\", \"workflowToStateName\"],\n",
        "            how=\"left\"\n",
        "        )\n",
        "\n",
        "        final_cols = [\n",
        "            \"name\",\n",
        "            \"workflowFromStateName\",\n",
        "            \"workflowToStateName\",\n",
        "            \"workflowFormName\",\n",
        "            \"sla_time\",\n",
        "            \"sla_time_type\",\n",
        "            \"fromToStateName\"\n",
        "        ]\n",
        "        merged_df = merged_df[final_cols]\n",
        "\n",
        "        if \"Transition_mapping\" in wb.sheetnames:\n",
        "            wb.remove(wb[\"Transition_mapping\"])\n",
        "        ws_map = wb.create_sheet(\"Transition_mapping\")\n",
        "\n",
        "        for c_idx, header in enumerate(final_cols, start=1):\n",
        "            ws_map.cell(row=1, column=c_idx, value=header)\n",
        "        for r_idx, row in enumerate(merged_df.values, start=2):\n",
        "            for c_idx, value in enumerate(row, start=1):\n",
        "                ws_map.cell(row=r_idx, column=c_idx, value=value)\n",
        "\n",
        "        # Add Transition_mapping to final list\n",
        "        created_sheets.append(\"Transition_mapping\")\n",
        "\n",
        "        # ============================================================\n",
        "        # Save final workbook in session_state\n",
        "        # ============================================================\n",
        "        wb.save(output)\n",
        "        st.session_state.processed_output = output.getvalue()\n",
        "        st.session_state.created_sheets = created_sheets\n",
        "\n",
        "    # Use processed_output from session_state for download\n",
        "    st.success(f\"Modified Excel created successfully!\")\n",
        "    st.download_button(\n",
        "        label=\"Download Final Excel\",\n",
        "        data=st.session_state.processed_output,\n",
        "        file_name=f\"Processed_{original_file_name}\",\n",
        "        mime=\"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\"\n",
        "    )\n",
        "\n",
        "    # Show final sheets list after processing and download\n",
        "    with st.container():\n",
        "        st.markdown(\"**Sheets created:**\")\n",
        "        st.markdown(\n",
        "            \"<div style='max-height:250px; overflow-y:auto;'>\"\n",
        "            + \"<br>\".join([f\"{idx+1}. {name}\" for idx, name in enumerate(st.session_state.created_sheets)])\n",
        "            + \"</div>\",\n",
        "            unsafe_allow_html=True\n",
        "        )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qifiVIdmOFm5",
        "outputId": "b0ede760-8184-4346-eaaa-f8863b4d3fbb"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install packages (if not installed already)\n",
        "!pip install streamlit pyngrok openpyxl --quiet\n",
        "\n",
        "from pyngrok import ngrok\n",
        "import time\n",
        "\n",
        "# Kill previous tunnels\n",
        "ngrok.kill()\n",
        "\n",
        "# Set your ngrok token\n",
        "ngrok.set_auth_token(\"35gXlCpbnwCAIJ9I2xiA1GXDu2u_3UoQf6QeGYhFC9MxYapgo\")\n",
        "\n",
        "# Start Streamlit in the background\n",
        "get_ipython().system_raw(\"streamlit run app.py &\")\n",
        "\n",
        "# Wait a few seconds for Streamlit to start\n",
        "time.sleep(5)\n",
        "\n",
        "# Open ngrok tunnel\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"Streamlit app running at:\", public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uUCQC3NOHSa",
        "outputId": "5174a1b0-8c14-452f-bec3-2a262bfedcaa"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit app running at: NgrokTunnel: \"https://armless-twirly-alanna.ngrok-free.dev\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    }
  ]
}
